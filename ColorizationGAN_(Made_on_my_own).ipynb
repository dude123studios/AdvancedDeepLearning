{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColorizationGAN (Made on my own)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx6zc84DCpO2259iOP7dEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/AdvancedDeepLearning/blob/main/ColorizationGAN_(Made_on_my_own).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVwvbCoWwlRY"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import cv2 \r\n",
        "from tensorflow.keras.losses import mean_squared_error\r\n",
        "from tensorflow.keras.losses import mean_absolute_error\r\n",
        "import random \r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cZ_fSji2tHZ",
        "outputId": "8dfec076-5781-480f-dbd1-6484aaff4193"
      },
      "source": [
        "(data,_),(test,_) = tf.keras.datasets.cifar10.load_data()\r\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWlgwDtC3zYG",
        "outputId": "9143ff5f-1c10-4a0f-9f0a-c90ec08d32bf"
      },
      "source": [
        "def grayConversion(image):\r\n",
        "    #                   blue                    green                   red\r\n",
        "    grayValue = 0.07 * image[:,:,2] + 0.72 * image[:,:,1] + 0.21 * image[:,:,0]\r\n",
        "    gray_img = grayValue.astype(np.uint8)\r\n",
        "    return gray_img\r\n",
        "new_arr = []\r\n",
        "for img in data:\r\n",
        "  img = grayConversion(img)\r\n",
        "  new_arr.append(img)\r\n",
        "gray = np.asarray(new_arr)\r\n",
        "gray = gray.astype('float32')\r\n",
        "gray = gray.reshape((50000,32,32,1))\r\n",
        "print(gray.shape)\r\n",
        "\r\n",
        "new_arr = []\r\n",
        "for img in test:\r\n",
        "  img = grayConversion(img)\r\n",
        "  new_arr.append(img)\r\n",
        "gray_test = np.asarray(new_arr)\r\n",
        "gray_test = gray_test.astype('float32')\r\n",
        "gray_test = gray_test.reshape((10000,32,32,1))\r\n",
        "print(gray_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 1)\n",
            "(10000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5CEjzt61jsh"
      },
      "source": [
        "def downsample(filters, size=3, apply_batchnorm=True):\r\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "\r\n",
        "    result = tf.keras.Sequential()\r\n",
        "    result.add(\r\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\r\n",
        "                             kernel_initializer=initializer, use_bias=False))\r\n",
        "    if apply_batchnorm:\r\n",
        "        result.add(tf.keras.layers.BatchNormalization())\r\n",
        "    result.add(tf.keras.layers.LeakyReLU())\r\n",
        "\r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKx4V4PV126m"
      },
      "source": [
        "def upsample(filters, size=3, apply_dropout=False):\r\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "\r\n",
        "    result = tf.keras.Sequential()\r\n",
        "    result.add(\r\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\r\n",
        "                                    padding='same',\r\n",
        "                                    kernel_initializer=initializer,\r\n",
        "                                    use_bias=False))\r\n",
        "\r\n",
        "    result.add(tf.keras.layers.BatchNormalization())\r\n",
        "\r\n",
        "    if apply_dropout:\r\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\r\n",
        "\r\n",
        "    result.add(tf.keras.layers.ReLU())\r\n",
        "\r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN5PZ7On14gp"
      },
      "source": [
        "class ResnetIdentityBlock(tf.keras.Model):\r\n",
        "  def __init__(self, kernel_size, filters):\r\n",
        "    super(ResnetIdentityBlock, self).__init__(name='')\r\n",
        "    filters1, filters2, filters3 = filters\r\n",
        "\r\n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\r\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\r\n",
        "\r\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\r\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization()\r\n",
        "\r\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\r\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization()\r\n",
        "\r\n",
        "  def call(self, input_tensor, training=False):\r\n",
        "    x = self.conv2a(input_tensor)\r\n",
        "    x = self.bn2a(x, training=training)\r\n",
        "    x = tf.nn.relu(x)\r\n",
        "\r\n",
        "    x = self.conv2b(x)\r\n",
        "    x = self.bn2b(x, training=training)\r\n",
        "    x = tf.nn.relu(x)\r\n",
        "\r\n",
        "    x = self.conv2c(x)\r\n",
        "    x = self.bn2c(x, training=training)\r\n",
        "\r\n",
        "    x += input_tensor\r\n",
        "    return tf.nn.relu(x)\r\n",
        "\r\n",
        "    \r\n",
        "block1 = ResnetIdentityBlock(3, [128, 128, 128])\r\n",
        "block2 = ResnetIdentityBlock(3, [128, 128,128])\r\n",
        "block3 = ResnetIdentityBlock(3, [128, 128, 128])\r\n",
        "\r\n",
        "\r\n",
        "resnet = [block1, block2, block3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWX-DcB17NL"
      },
      "source": [
        "\r\n",
        "def Generator():\r\n",
        "    down_stack = [\r\n",
        "        downsample(32, 3, apply_batchnorm=False), \r\n",
        "        downsample(64, 3),\r\n",
        "        downsample(128, 3), \r\n",
        "    ]\r\n",
        "\r\n",
        "    up_stack = [\r\n",
        "        upsample(64, 3),\r\n",
        "        upsample(32, 3), \r\n",
        "    ]\r\n",
        "\r\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "    last = tf.keras.layers.Conv2DTranspose(3, 3,\r\n",
        "                                         strides=2,\r\n",
        "                                         padding='same',\r\n",
        "                                         kernel_initializer=initializer,\r\n",
        "                                         activation='sigmoid') \r\n",
        "\r\n",
        "\r\n",
        "    inputs = tf.keras.layers.Input(shape=[32, 32, 1])\r\n",
        "    x = inputs\r\n",
        "\r\n",
        "    # Downsampling through the model\r\n",
        "    skips = []\r\n",
        "    for down in down_stack:\r\n",
        "        x = down(x)\r\n",
        "        skips.append(x)\r\n",
        "        \r\n",
        "    for block in resnet:\r\n",
        "        x = block(x)\r\n",
        "\r\n",
        "    skips = reversed(skips[:-1])\r\n",
        "\r\n",
        "    # Upsampling and establishing the skip connections\r\n",
        "    for up, skip in zip(up_stack, skips):\r\n",
        "        concat = tf.keras.layers.Concatenate()\r\n",
        "        x = up(x)\r\n",
        "        x = concat([x, skip])\r\n",
        "\r\n",
        "    x = last(x)\r\n",
        "\r\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdHoRGQR1-GU"
      },
      "source": [
        "def Discriminator():\r\n",
        "    inputs = tf.keras.layers.Input(shape=[None,None,3])\r\n",
        "    x = inputs\r\n",
        "    g_filter = 32\r\n",
        "    \r\n",
        "    down_stack = [\r\n",
        "        downsample(g_filter),\r\n",
        "        downsample(g_filter * 2),\r\n",
        "        downsample(g_filter * 4),\r\n",
        "    ]\r\n",
        "    \r\n",
        "    for down in down_stack:\r\n",
        "        x = down(x)\r\n",
        "\r\n",
        "    last = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same') \r\n",
        "    x = last(x)\r\n",
        "\r\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IchdjNfeQxLf"
      },
      "source": [
        "generator = Generator()\r\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4MMK0pRj81f"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "optimizer = tf.keras.optimizers.Adam(beta_1=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbt62qI2WVwR"
      },
      "source": [
        "@tf.function\r\n",
        "def grayConversionTensors(imgs):  \r\n",
        "  return tf.math.add(tf.math.add(tf.slice(imgs,[0,0,0,0],[-1,-1,-1,1])*0.21,tf.slice(imgs,[0,0,0,1],[-1,-1,-1,1])*0.72), 0.07 * tf.slice(imgs,[0,0,0,2],[-1,-1,-1,1]))\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBQVGclQfsqT"
      },
      "source": [
        "@tf.function\r\n",
        "def train_batch(gray_imgs,normal_imgs):\r\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
        "    fake_imgs = generator(gray_imgs,training=True)\r\n",
        "    \r\n",
        "    logits_real = discriminator(normal_imgs,training=True)\r\n",
        "    logits_fake = discriminator(fake_imgs,training=True)\r\n",
        "\r\n",
        "    rl_loss = loss(tf.ones_like(logits_real),logits_real)\r\n",
        "    fk_loss = loss(tf.zeros_like(logits_fake),logits_fake)\r\n",
        "    disc_loss = rl_loss + fk_loss\r\n",
        "    \r\n",
        "    gray_color_imgs = grayConversionTensors(fake_imgs)\r\n",
        "\r\n",
        "    gen_loss = tf.math.reduce_sum([\r\n",
        "        tf.math.reduce_mean(loss(tf.ones_like(logits_fake),logits_fake)),\r\n",
        "        tf.math.reduce_mean(tf.square(gray_color_imgs-gray_imgs)),\r\n",
        "      ])\r\n",
        "    \r\n",
        "    grad = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(grad,discriminator.trainable_variables))\r\n",
        "    grad = gen_tape.gradient(gen_loss,generator.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(grad,generator.trainable_variables))\r\n",
        "\r\n",
        "    return disc_loss, gen_loss\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IwwJOHTraGO"
      },
      "source": [
        "\r\n",
        "def train(gray_imgs,real_imgs,test_gray_imgs,test_real_imgs,epochs=50,batch_size=10):\r\n",
        "  batches_per_epoch = int(gray_imgs.shape[0]/batch_size)\r\n",
        "  for epoch in range(epochs):\r\n",
        "    for batch in range(0,batches_per_epoch-1):\r\n",
        "      batch_imgs_x = gray_imgs[batch*batch_size:(batch+1)*batch_size]\r\n",
        "      batch_imgs_y = real_imgs[batch*batch_size:batch*batch_size+batch_size]\r\n",
        "      disc_loss, gen_loss = train_batch(batch_imgs_x,batch_imgs_y)\r\n",
        "      if batch == 0:\r\n",
        "          print(\"discriminator: \", disc_loss.numpy)\r\n",
        "          print(\"generator: {}\\n\".format(gen_loss.numpy))\r\n",
        "          '''\r\n",
        "          idx = random.randint(0,9999)\r\n",
        "          fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharey=True, sharex=True)\r\n",
        "          gen_outputA = generator(test_gray_imgs[idx], training=False)\r\n",
        "          axs[0,0].imshow(test_gray_imgs[idx])\r\n",
        "          axs[0,0].set_title(\"Gray Image\")\r\n",
        "          axs[1,0].imshow(gen_outputA[0])\r\n",
        "          axs[1,0].set_title(\"Synthesized Image\")\r\n",
        "          axs[2,0].imshow(test_real_imgs[0])\r\n",
        "          axs[2,0].set_title(\"Real Image\")\r\n",
        "          plt.show()\r\n",
        "          '''\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOfcdwi2iNVK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "8b2383db-4d29-40df-9cf4-4068ce65b7bd"
      },
      "source": [
        "with tf.device('gpu:0'):\r\n",
        "  train(gray,data,gray_test,test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=1.5549645>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16414.893>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=0.0009520419>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16320.184>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=3.2652257e-05>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16321.565>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=6.507985e-05>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16324.986>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=4.36134e-06>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16324.295>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=8.098054e-06>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16327.236>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=1.2051195e-06>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16325.813>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=1.2340707e-05>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16329.177>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=1.2736771e-06>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16327.852>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=8.085106e-06>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16332.262>>\n",
            "\n",
            "discriminator:  <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=7.360958e-07>>\n",
            "generator: <bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=float32, numpy=16330.855>>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d8c46e23ac08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgray_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-995e0a347d05>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gray_imgs, real_imgs, test_gray_imgs, test_real_imgs, epochs, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mbatch_imgs_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mbatch_imgs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_imgs_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_imgs_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"discriminator: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}