{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colorization AutoEncoder",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU+oDJr3A9qTV7eTp+W9zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/AdvancedDeepLearning/blob/main/Colorization_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByWoqhvEIslo"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHy302vrfolj"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, ReLU, Conv2D, UpSampling2D, MaxPooling2D, Activation,BatchNormalization, Dropout,Input,Concatenate,Flatten,Reshape\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-hV0SGGIvuc"
      },
      "source": [
        "Define a method to convert real images to gray images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWauj9UOhTQ8"
      },
      "source": [
        "def get_gray_images(colored_images):\r\n",
        "  #                       blue                              green                            red\r\n",
        "  grayValues = 0.07 * colored_images[:,:,:,2] + 0.72 * colored_images[:,:,:,1] + 0.21 * colored_images[:,:,:,0]\r\n",
        "  gray_images = (grayValues/225).astype(np.float32)\r\n",
        "  gray_images = gray_images.reshape((gray_images.shape[0],gray_images.shape[1],gray_images.shape[2],1))\r\n",
        "  return gray_images"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMLfgY1sIz4u"
      },
      "source": [
        "Define a method to load our dataset and get gray images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWi4n-xdiYQh"
      },
      "source": [
        "def load_dataset():\r\n",
        "  (x_train,_),(x_test,_) = cifar10.load_data()\r\n",
        "  return (x_train,get_gray_images(x_train)), (x_test,get_gray_images(x_test))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwJbD2Z99c_f"
      },
      "source": [
        "Define a downsample block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97QMLTj01Jre"
      },
      "source": [
        "def downsample(filters,dropout=False,pool=True):\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "  model.add(Conv2D(filters,(3,3),padding='same'))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  model.add(ReLU())\r\n",
        "  if pool:\r\n",
        "    model.add(MaxPooling2D(2,2))\r\n",
        "  if dropout:\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "  return model  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP3vAwIWJGWJ"
      },
      "source": [
        "Define an upsample block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5m78StV2Ryh"
      },
      "source": [
        "def upsample(filters,up=True):\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "  model.add(Conv2D(filters,(3,3),padding='same'))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  model.add(ReLU())\r\n",
        "  if up:\r\n",
        "    model.add(UpSampling2D())\r\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gxhE_Pw9ycO"
      },
      "source": [
        "Define Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG5KoVx491O0"
      },
      "source": [
        "def latent_space():\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "  model.add(Flatten())\r\n",
        "  model.add(Dense(512,input_dim=(1024,),activation='relu'))\r\n",
        "  model.add(Dense(256,activation='relu'))\r\n",
        "  model.add(Dense(512,activation='relu'))\r\n",
        "  model.add(Reshape((2,2,128)))\r\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZKBEf95JJGt"
      },
      "source": [
        "Finally, define the entire auto encoder similar to a U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyC2QgzuqXl5"
      },
      "source": [
        "def AutoEncoder():\r\n",
        "  inputs = Input(shape=[32,32,1])\r\n",
        "  skips = []\r\n",
        "  x = downsample(32)(inputs)\r\n",
        "  skips.append(x)\r\n",
        "  x = downsample(64,dropout=True)(x)\r\n",
        "  skips.append(x)\r\n",
        "  x = downsample(128)(x)\r\n",
        "  skips.append(x)\r\n",
        "  x = downsample(256,dropout=True)(x)\r\n",
        "\r\n",
        "  x = latent_space()(x)\r\n",
        "  \r\n",
        "  x = upsample(256)(x)\r\n",
        "  concat1 = Concatenate()\r\n",
        "  x = upsample(128)(concat1([x,skips[2]]))\r\n",
        "  concat2 = Concatenate()\r\n",
        "  x = upsample(64)(concat2([x,skips[1]]))\r\n",
        "  concat3 = Concatenate()\r\n",
        "  x = upsample(32)(concat3([x,skips[0]]))\r\n",
        "\r\n",
        "  x = Conv2D(3, (3,3),padding='same',activation='relu')(x)\r\n",
        "\r\n",
        "  return tf.keras.models.Model(inputs,x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up8csLGVJOLC"
      },
      "source": [
        "Define a method to compile our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsncqIcXEiTf"
      },
      "source": [
        "def compile(model):\r\n",
        "  optimizer = Adam(learning_rate=0.001)\r\n",
        "  model.compile(loss='mse',optimizer=optimizer,metrics=[tf.keras.metrics.MeanSquaredError()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwcAsmfIJRf9"
      },
      "source": [
        "Define a method to train with a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ImZQ2wGnp9"
      },
      "source": [
        "def train(model,gray,real,gray_test,real_test,epochs=50,batch_size=128):\r\n",
        "  with tf.device('gpu:0'):\r\n",
        "    history = model.fit(gray,real,epochs=epochs,batch_size=batch_size,validation_data=(gray_test,real_test))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owbDT-r_JT3a"
      },
      "source": [
        "Finally, train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYsGturXHgwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120af4ff-1752-484d-df56-96e5b0811b50"
      },
      "source": [
        "(real,gray),(real_test,gray_test) = load_dataset()\r\n",
        "model = AutoEncoder()\r\n",
        "model.summary()\r\n",
        "compile(model)\r\n",
        "train(model,gray,real,gray_test,real_test,epochs=50)\r\n",
        "model.save('colorization_autoencoder.h5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 16, 16, 32)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 8, 8, 64)     18752       sequential[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4, 4, 128)    74368       sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 2, 2, 256)    296192      sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 2, 2, 128)    787712      sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 4, 4, 256)    296192      sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 4, 384)    0           sequential_5[0][0]               \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       (None, 8, 8, 128)    443008      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 192)    0           sequential_6[0][0]               \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_7 (Sequential)       (None, 16, 16, 64)   110912      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 96)   0           sequential_7[0][0]               \n",
            "                                                                 sequential[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_8 (Sequential)       (None, 32, 32, 32)   27808       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 3)    867         sequential_8[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,056,259\n",
            "Trainable params: 2,054,339\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 11s 20ms/step - loss: 13326.3927 - mean_squared_error: 13326.3927 - val_loss: 5089.8027 - val_mean_squared_error: 5089.8027\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 1302.6535 - mean_squared_error: 1302.6535 - val_loss: 813.7369 - val_mean_squared_error: 813.7369\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 670.0507 - mean_squared_error: 670.0507 - val_loss: 703.5344 - val_mean_squared_error: 703.5344\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 608.2358 - mean_squared_error: 608.2358 - val_loss: 724.9827 - val_mean_squared_error: 724.9827\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 543.2166 - mean_squared_error: 543.2166 - val_loss: 628.4995 - val_mean_squared_error: 628.4995\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 493.4918 - mean_squared_error: 493.4918 - val_loss: 473.0379 - val_mean_squared_error: 473.0379\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 463.8593 - mean_squared_error: 463.8593 - val_loss: 551.5316 - val_mean_squared_error: 551.5316\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 442.8151 - mean_squared_error: 442.8151 - val_loss: 447.1027 - val_mean_squared_error: 447.1027\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 426.0098 - mean_squared_error: 426.0098 - val_loss: 532.4541 - val_mean_squared_error: 532.4541\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 412.8499 - mean_squared_error: 412.8499 - val_loss: 419.2124 - val_mean_squared_error: 419.2124\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 409.1082 - mean_squared_error: 409.1082 - val_loss: 453.4011 - val_mean_squared_error: 453.4011\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 394.0958 - mean_squared_error: 394.0958 - val_loss: 533.2994 - val_mean_squared_error: 533.2994\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 388.4600 - mean_squared_error: 388.4600 - val_loss: 471.3232 - val_mean_squared_error: 471.3232\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 380.4062 - mean_squared_error: 380.4062 - val_loss: 403.2649 - val_mean_squared_error: 403.2649\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 371.0600 - mean_squared_error: 371.0600 - val_loss: 381.9590 - val_mean_squared_error: 381.9590\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 365.9586 - mean_squared_error: 365.9586 - val_loss: 394.4155 - val_mean_squared_error: 394.4155\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 362.8026 - mean_squared_error: 362.8026 - val_loss: 388.7185 - val_mean_squared_error: 388.7185\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 359.0838 - mean_squared_error: 359.0838 - val_loss: 424.0344 - val_mean_squared_error: 424.0344\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 352.9797 - mean_squared_error: 352.9797 - val_loss: 460.6138 - val_mean_squared_error: 460.6138\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 344.5600 - mean_squared_error: 344.5600 - val_loss: 381.3878 - val_mean_squared_error: 381.3878\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 340.2104 - mean_squared_error: 340.2104 - val_loss: 414.8153 - val_mean_squared_error: 414.8153\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 337.3461 - mean_squared_error: 337.3461 - val_loss: 384.8471 - val_mean_squared_error: 384.8471\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 331.1987 - mean_squared_error: 331.1987 - val_loss: 387.4381 - val_mean_squared_error: 387.4381\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 328.2088 - mean_squared_error: 328.2088 - val_loss: 479.3506 - val_mean_squared_error: 479.3506\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 327.3118 - mean_squared_error: 327.3118 - val_loss: 405.5581 - val_mean_squared_error: 405.5581\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 321.5754 - mean_squared_error: 321.5754 - val_loss: 416.4452 - val_mean_squared_error: 416.4452\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 319.8230 - mean_squared_error: 319.8230 - val_loss: 452.3818 - val_mean_squared_error: 452.3818\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 312.9723 - mean_squared_error: 312.9723 - val_loss: 391.7805 - val_mean_squared_error: 391.7805\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 310.8949 - mean_squared_error: 310.8949 - val_loss: 409.3276 - val_mean_squared_error: 409.3276\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 303.2351 - mean_squared_error: 303.2351 - val_loss: 380.5090 - val_mean_squared_error: 380.5090\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 302.0373 - mean_squared_error: 302.0373 - val_loss: 391.0283 - val_mean_squared_error: 391.0283\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 300.2450 - mean_squared_error: 300.2450 - val_loss: 371.6515 - val_mean_squared_error: 371.6515\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 298.3595 - mean_squared_error: 298.3595 - val_loss: 438.5303 - val_mean_squared_error: 438.5303\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 292.9523 - mean_squared_error: 292.9523 - val_loss: 472.8387 - val_mean_squared_error: 472.8387\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 287.4152 - mean_squared_error: 287.4152 - val_loss: 404.6785 - val_mean_squared_error: 404.6785\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 289.0593 - mean_squared_error: 289.0593 - val_loss: 372.6753 - val_mean_squared_error: 372.6753\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 284.1861 - mean_squared_error: 284.1861 - val_loss: 373.5254 - val_mean_squared_error: 373.5254\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 285.3702 - mean_squared_error: 285.3702 - val_loss: 371.3974 - val_mean_squared_error: 371.3974\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 281.1519 - mean_squared_error: 281.1519 - val_loss: 431.9006 - val_mean_squared_error: 431.9006\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 278.9531 - mean_squared_error: 278.9531 - val_loss: 386.7875 - val_mean_squared_error: 386.7875\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 276.0560 - mean_squared_error: 276.0560 - val_loss: 375.4704 - val_mean_squared_error: 375.4704\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 271.4824 - mean_squared_error: 271.4824 - val_loss: 422.3259 - val_mean_squared_error: 422.3259\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 272.4420 - mean_squared_error: 272.4420 - val_loss: 362.0595 - val_mean_squared_error: 362.0595\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 267.4364 - mean_squared_error: 267.4364 - val_loss: 399.7665 - val_mean_squared_error: 399.7665\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 269.5178 - mean_squared_error: 269.5178 - val_loss: 405.5512 - val_mean_squared_error: 405.5512\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 262.6152 - mean_squared_error: 262.6152 - val_loss: 393.6892 - val_mean_squared_error: 393.6892\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 264.2708 - mean_squared_error: 264.2708 - val_loss: 369.9765 - val_mean_squared_error: 369.9765\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 260.2629 - mean_squared_error: 260.2629 - val_loss: 376.5522 - val_mean_squared_error: 376.5522\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 261.3267 - mean_squared_error: 261.3267 - val_loss: 387.9867 - val_mean_squared_error: 387.9867\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 259.2915 - mean_squared_error: 259.2915 - val_loss: 440.5967 - val_mean_squared_error: 440.5967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajvfUAdjER7h"
      },
      "source": [
        "**Colorization** is a hard task, and I'm sure with **100**-**200**~ epochs we would converge to an error of about **100**. This is really good, because with a batch size of **128**, the error of an entire image is around **0.25**. You can go to the colab and try it yourself. The biggest bottleneck for this task, however, is the fact that the images are only **32 x 32**. If I used a better dataset, such as the Yosemite dataset, this would work a lot better. However, that is a test for another day. At a sence, colorization is segmantic segmentation, with a color gradient(shading, not computational)"
      ]
    }
  ]
}