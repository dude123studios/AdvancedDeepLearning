{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embeddings with Gensim",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL+KrmUVqIcWqGy6aMXfsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/AdvancedDeepLearning/blob/main/Embeddings_with_Gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DXvleCYteEt"
      },
      "source": [
        "import gensim.downloader as api\r\n",
        "from gensim.models import Word2Vec\r\n",
        "\r\n",
        "dataset = api.load('text8')\r\n",
        "model = Word2Vec(dataset)\r\n",
        "\r\n",
        "model.save('data/text8-word2vec.bin')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_86xOtRuq1s",
        "outputId": "ee051147-b26b-4e1c-bcc0-0a535b3ade2f"
      },
      "source": [
        "from gensim.models import KeyedVectors\r\n",
        "\r\n",
        "model = KeyedVectors.load('data/text8-word2vec.bin')\r\n",
        "word_vectors = model.wv\r\n",
        "\r\n",
        "words = word_vectors.vocab.keys()\r\n",
        "print([x for i,x in enumerate(words) if i<10])\r\n",
        "assert('king' in words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8zJl73BTRP0",
        "outputId": "6a0743a9-de43-404a-fd0f-310b1ae31c1e"
      },
      "source": [
        "def print_most_similar(word_conf_pairs,k):\r\n",
        "  for i, (word,conf) in enumerate(word_conf_pairs):\r\n",
        "    print('{:.3f} {:s}'.format(conf,word))\r\n",
        "    if i >= k-1:\r\n",
        "      break\r\n",
        "  if k < len(word_conf_pairs):\r\n",
        "    print('...')\r\n",
        "\r\n",
        "print_most_similar(word_vectors.most_similar('king'),5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.728 prince\n",
            "0.719 queen\n",
            "0.704 emperor\n",
            "0.697 kings\n",
            "0.694 throne\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9m_VIPAV0mj"
      },
      "source": [
        "We can do arimthmatic, for example, paris:france ~ berlin:germany"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y672zJSjVOJo",
        "outputId": "e9058ad2-282d-4b53-eb62-95ee89d9399f"
      },
      "source": [
        "print_most_similar(word_vectors.most_similar(positive=['france','berlin'],negative=['paris']),1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.773 germany\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcCmHqP-WH1D"
      },
      "source": [
        "Cosine similarity is a better measure of similarity in embedding space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCsp6PUTWPCQ",
        "outputId": "6c6208d6-834c-4da2-a24d-a5e17d74e675"
      },
      "source": [
        "print_most_similar(word_vectors.most_similar_cosmul(positive=['france','berlin'],negative=['paris']),1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.935 germany\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63-1ihDmWyf5"
      },
      "source": [
        "As you can the confidence score was significantly higher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKUdaezBY-Y9"
      },
      "source": [
        "Now we can expiremnt with out of place words. In this example, the word, \"random,\" is clearly out of place with the fruits "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4MwDOubW6Ms",
        "outputId": "b03f8257-9814-4b15-d462-cf6e187d192c"
      },
      "source": [
        "print(word_vectors.doesnt_match(['apples','oranges','random','bananas','grapes']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4FPn-vZ8Ff"
      },
      "source": [
        "We can also calculate the similarity between words like so"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtLF9mPlZR8B",
        "outputId": "41152fc9-e193-4c40-e0f5-ffc4faf96ac7"
      },
      "source": [
        "words = ['apples','oranges','bananas','car','tree','rollercoaster']\r\n",
        "for word in words:\r\n",
        "  print('similarity(grapes,{:s}) = {:.3f}'.format(word,word_vectors.similarity('grapes',word)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarity(grapes,apples) = 0.775\n",
            "similarity(grapes,oranges) = 0.727\n",
            "similarity(grapes,bananas) = 0.610\n",
            "similarity(grapes,car) = 0.063\n",
            "similarity(grapes,tree) = 0.495\n",
            "similarity(grapes,rollercoaster) = 0.307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HwCm9RXaB3S"
      },
      "source": [
        "grapes are similar to apples, oranges, and bananas, somewhat similar to trees, and not similar to cars at all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNiCPfPpaTjm",
        "outputId": "3c34ba60-bddd-4de0-9439-1573f70a063f"
      },
      "source": [
        "print_most_similar(word_vectors.similar_by_word('singapore'),5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.878 malaysia\n",
            "0.840 indonesia\n",
            "0.833 uganda\n",
            "0.829 brunei\n",
            "0.823 barbados\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASAQS-q0a6Xg"
      },
      "source": [
        "We can also compute distance between word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pHodu_Ca-IO",
        "outputId": "2a7274a6-51ec-4310-f9ff-59cf30b0a90b"
      },
      "source": [
        "print('distance(singapore, malaysia) = '+ str(word_vectors.distance('singapore','malaysia')))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distance(singapore, malaysia) = 0.12174350023269653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2piiiIojbS31"
      },
      "source": [
        "In addition, we can use specific word vectors for specific words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDjdVWRMbXfB",
        "outputId": "eeeb0146-b08f-4383-b1b6-5f600e7aead4"
      },
      "source": [
        "vec_apple = word_vectors['apple']\r\n",
        "print(vec_apple)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.03849123  2.0464475  -1.5543152   0.425766    0.39379004 -0.6558501\n",
            "  0.85083926 -0.04886514  0.6428664   0.41137114  0.5111856   2.4500477\n",
            " -0.6449271   0.6567483  -3.785012   -0.30663005  1.1449054   1.7108201\n",
            "  0.010325   -0.12602803  0.7945448  -2.6246612  -1.01991     1.6095597\n",
            "  0.22073463  0.8946597  -0.27490544 -0.32423925 -0.6489213  -0.33749405\n",
            " -0.25108802  2.0312889  -0.75423306 -0.57523495 -2.0655732  -0.28978768\n",
            "  0.02136061 -1.6766669  -0.27531907  1.5908382  -2.655386    2.7505744\n",
            " -1.7928637   0.9573799   0.24740696 -0.49393222 -2.4332561   2.3486032\n",
            "  1.7046545  -0.44828755  0.39563498 -1.1315526  -0.31336647 -1.3206514\n",
            "  0.08113258  2.1907551   2.0735445   1.8546292   0.2900023   4.32731\n",
            " -1.0502985   0.25231117  1.0018309  -2.5597386  -0.2105543  -0.74183244\n",
            "  1.9333822   1.4301778   0.57632947  1.7417641  -2.2287362  -1.222632\n",
            "  0.197973   -1.0327437   2.3882747   0.3089105  -0.77825034  1.2305263\n",
            " -0.81766325 -0.40372443 -0.67805296 -1.8627924   0.81034505  0.5265403\n",
            " -1.5963552  -1.7036486  -1.8217374  -0.16859075  2.2599883   0.42835605\n",
            "  0.11673138 -1.1205758   0.09687723 -0.15321477 -0.7180083   0.9438987\n",
            "  0.06852008 -0.45495498  0.6998469  -1.1497025 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}